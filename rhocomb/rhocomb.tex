\documentclass{llncs}
\usepackage{mathpartir}
\usepackage{bigpage}
\usepackage{bcprules}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{stmaryrd}

\newcommand{\new}{\mathsf{new}}
\newcommand{\interp}[1]{\llbracket #1 \rrbracket}
\newcommand{\maps}{\colon}
\newcommand{\Th}{\mathrm{Th}}
\newcommand{\Gph}{\mathrm{Gph}}
\newcommand{\FinSet}{\mathrm{FinSet}}
\newcommand{\FPGphCat}{\mathrm{FPGphCat}}
\newcommand{\Set}{\mathrm{Set}}
\newcommand{\Cat}{\mathrm{Cat}}
\newcommand{\Calc}{\mathrm{Calc}}
\newcommand{\Mon}{\mathrm{Mon}}
\newcommand{\BoolAlg}{\mathrm{BoolAlg}}
\renewcommand{\Form}{\mathrm{Form}}
\newcommand{\leftu}{\mathrm{left}}
\newcommand{\rightu}{\mathrm{right}}
\newcommand{\send}{\mathrm{send}}
\newcommand{\recv}{\mathrm{recv}}
\newcommand{\comm}{\mathrm{comm}}
\renewcommand{\quote}[1]{``#1"}
\newcommand{\deref}[1]{\mathrm{eval}(#1)}
\newcommand{\op}{\mathrm{op}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\pic}{$\pi$-calculus}

% Double brackets
\newcommand{\ldb}{[\![}
\newcommand{\rdb}{]\!]}
\newcommand{\ldrb}{(\!(}
\newcommand{\rdrb}{)\!)}
\newcommand{\lrbb}{(\!|}
\newcommand{\rrbb}{|\!)}
\newcommand{\lliftb}{\langle\!|}
\newcommand{\rliftb}{|\!\rangle}
%\newcommand{\plogp}{:\!-}
\newcommand{\plogp}{\leftarrow}
%\newcommand{\plogp}{\coloneq}
% \newcommand{\lpquote}{\langle}
% \newcommand{\rpquote}{\rangle}
% \newcommand{\lpquote}{\lceil}
% \newcommand{\rpquote}{\rceil}
\newcommand{\lpquote}{\ulcorner}
\newcommand{\rpquote}{\urcorner}
\newcommand{\wbbisim}{\stackrel{\centerdot}{\approx}} %weak barbed bisimilar

% SYNTAX
\newcommand{\id}[1]{\texttt{#1}}
\newcommand{\none}{\emptyset}
\newcommand{\eps}{\epsilon}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\rep}[2]{\id{\{$#1$,$#2$\}}}
\newcommand{\elt}[2]{\id{$#1$[$#2$]}}
\newcommand{\infinity}{$\infty$}

\newcommand{\pzero}{\mathbin{0}}
\newcommand{\seq}{\mathbin{\id{,}}}
\newcommand{\all}{\mathbin{\id{\&}}}
\newcommand{\choice}{\mathbin{\id{|}}}
\newcommand{\altern}{\mathbin{\id{+}}}
\newcommand{\juxtap}{\mathbin{\id{|}}}
\newcommand{\concat}{\mathbin{.}}
\newcommand{\punify}{\mathbin{\id{:=:}}}
\newcommand{\fuse}{\mathbin{\id{=}}}
\newcommand{\scong}{\mathbin{\equiv}}
\newcommand{\nameeq}{\mathbin{\equiv_N}}
\newcommand{\alphaeq}{\mathbin{\equiv_{\alpha}}}
\newcommand{\names}[1]{\mathbin{\mathcal{N}(#1)}}
\newcommand{\freenames}[1]{\mathbin{\mathsf{FN}(#1)}}
\newcommand{\boundnames}[1]{\mathbin{\mathsf{BN}(#1)}}
%\newcommand{\lift}[2]{\texttt{lift} \; #1 \concat #2}
\newcommand{\binpar}[2]{#1 | #2}
\newcommand{\outputp}[2]{#1!(#2)}
\newcommand{\prefix}[3]{#1?(#2) . #3}
\newcommand{\lift}[2]{#1 \lliftb #2 \rliftb}
\newcommand{\clift}[1]{\lliftb #1 \rliftb}
\newcommand{\quotep}[1]{\mathsf{@}#1}
\newcommand{\dropn}[1]{\mathsf{*}#1}
\newcommand{\procn}[1]{\stackrel{\vee}{x}}

\newcommand{\newp}[2]{(\newkw \; #1 ) #2}
\newcommand{\bangp}[1]{! #1}

\newcommand{\substp}[2]{\{ \quotep{#1} / \quotep{#2} \}}
\newcommand{\substn}[2]{\{ #1 / #2 \}}

\newcommand{\psubstp}[2]{\widehat{\substp{#1}{#2}}}
\newcommand{\psubstn}[2]{\widehat{\substn{#1}{#2}}}

\newcommand{\applyp}[2]{#1 \langle #2 \rangle}
\newcommand{\absp}[2]{( #1 ) #2}
\newcommand{\annihilate}[1]{#1^{\times}}
\newcommand{\dualize}[1]{#1^{\bullet}}

\newcommand{\transitions}[3]{\mathbin{#1 \stackrel{#2}{\longrightarrow} #3}}
\newcommand{\meaningof}[1]{\ldb #1 \rdb}
\newcommand{\pmeaningof}[1]{\ldb #1 \rdb}
\newcommand{\nmeaningof}[1]{\lrbb #1 \rrbb}

\newcommand{\Proc}{\mathbin{Proc}}
\newcommand{\QProc}{\quotep{\mathbin{Proc}}}

\newcommand{\bc}{\mathbin{\mathbf{::=}}}
\newcommand{\bm}{\mathbin{\mathbf\mid}}

\newcommand{\rel}[1]{\;{\mathcal #1}\;} %relation
\newcommand{\red}{\rightarrow}
\newcommand{\wred}{\Rightarrow}
\newcommand{\redhat}{\hat{\longrightarrow}}
\newcommand{\lred}[1]{\stackrel{#1}{\longrightarrow}} %transitions
\newcommand{\wlred}[1]{\stackrel{#1}{\Longrightarrow}}
\newcommand{\vect}[1]{\stackrel{\rightharpoonup}{#1}}

\newcommand{\rhoc}{$\rho$-calculus}

\makeatletter
\gdef\tshortstack{\@ifnextchar[\@tshortstack{\@tshortstack[c]}}
\gdef\@tshortstack[#1]{%
  \leavevmode
  \vtop\bgroup
    \baselineskip-\p@\lineskip 3\p@
    \let\mb@l\hss\let\mb@r\hss
    \expandafter\let\csname mb@#1\endcsname\relax
    \let\\\@stackcr
    \@ishortstack}
\makeatother

\title{Name-free combinators for concurrency}
\author{
L.G. Meredith\inst{1}\\
\and
Michael Stay\inst{2}\\
}
\institute{
  {RChain Cooperative}\\
  \email{\fontsize{8}{8}\selectfont greg@rchain.coop}
  \and
  {Pyrofex Corp.}\\
  \email{\fontsize{8}{8}\selectfont stay@pyrofex.net}\\
}
\begin{document}
\maketitle
\begin{abstract}
\noindent
  Yoshida demonstrated how to eliminate the bound names coming from
  the input prefix in the asynchronous {\pic}, but her combinators
  still depend on the $\new$ operator to bind names.
  We modify Yoshida's combinators by replacing $\new$ and replication
  with reflective operators to provide the first combinator calculus
  with no bound names into which the asynchronous {\pic} has a faithful
  embedding.  We also show that multisorted Lawvere theories enriched 
  over graphs suffice to capture the operational semantics of the calculus.
\end{abstract}

\section{Introduction}

Many term calculi, like $\lambda$-calculus or {\pic}, involve
binders for names, and the mathematics of bound variable names is
subtle.  Sch\"onfinkel introduced the SKI combinator calculus in 1924
to clarify the role of quantified variables in intuitionistic logic by
eliminating them \cite{finkel}; Curry developed Sch\"onfinkel's ideas
much further.  The recent work by Jamie Gabbay and Andrew Pitts
\cite{DBLP:journals/fac/GabbayP02} and others
\cite{DBLP:journals/jcss/Clouston14} on nominal set theory has put the
study of bound names and substitution on a much nicer foundation, but
there is still value in eliminating bound variables because of the
clear connection between combinators and logical axioms.  As
concurrency becomes more important to the practice of computer
science, it is worth attempting to eliminate bound variables or names
to study the resulting logics.

The {\pic} (\cite{milner91polyadicpi}) has two binders for names: the
$\new$ operator, which introduces a new name into scope, and the input
prefix, which introduces a name for labeling locations for
substitution.  Yoshida \cite{DBLP:journals/tcs/Yoshida02} describes an
elimination algorithm that gets rid of input prefixes, but not the
$\new$ operator.  Meredith and Radestock
\cite{DBLP:journals/entcs/MeredithR05} introduce reflective operators
into a higher-order {\pic} and implment $\new$ and replication in
terms of reflection.  Here, we present a fusion of those ideas: a
name-free concurrent combinator calculus into which Yoshida's
combinators have a faithful embedding.  The operational semantics of
the resulting calculus can be presented using a Lawvere theory
enriched over graphs.

Lawvere theories enriched over category-like structures such as graphs
and posets provide a nice framework for term rewriting
\cite{DBLP:conf/ctcs/LuethG97}: the underlying Lawvere theory provides
an algebraic signature and a structural congruence for the syntax of
terms, while the enrichment provides structure for encoding the
reduction relation on the terms.

\section{A reflective higher-order concurrent combinator calculus}

\subsection{Yoshida's original combinator calculus}

\begin{mathpar}
  \inferrule* [lab=atom] {} { P \bc 0 \;|\; m(a,b) \;|\; d(a,b,c) \;|\; k(a) \;|\; fw(a,b) \;|\; br(a,b) \;|\; bl(a,b) \;|\; s(a,b,c) }
  \and
  \inferrule* [lab=process] {} {\bm \; (\new\; a)P \;|\; P|P \;|\; !P}
\end{mathpar}

As in the {\pic}, the $\new$ operator is a binding operator
for names, so Yoshida's calculus also has a notion of free and bound names.

\begin{mathpar}
  \freenames{\pzero} := \emptyset
  \and
  \freenames{k(a)} := \{ a \}
  \and
  \freenames{m(a,b)} = \freenames{f(a,b)} = \freenames{br(a,b)} = \freenames{bl(a,b)} := \{ a, b \}
  \and
  \freenames{d(a,b,c)} = \freenames{s(a,b,c)} := \{ a, b, c \}
  \and
  \freenames{(\new\;a)P} := \freenames{P} \setminus \{ a \}
  \and
  \freenames{P|Q} := \freenames{P} \cup \freenames{Q}
  \and
  \freenames{!P} := \freenames{P}
\end{mathpar}

The bound names of a process, $\boundnames{P}$, are those names occurring in $P$
that are not free. For example, in $(\new\; b)m(a,b)$, the name $a$ is free, while $b$ is bound.

In the following definition, $\vect{x}$ indicates a list of names,
$u:\vect{x}$ indicates the concatenation of $u$ onto the vector, and
abuse set notation $u \in \vect{x}$ to assert or require that $u$
occurs in $\vect{x}$.

\begin{definition}
Two processes, $P,Q$, are alpha-equivalent if $P = Q\{\vect{y}/\vect{x}\}$ for
some $\vect{x} \in \boundnames{Q},\vect{y} \in \boundnames{P}$, where $Q\{\vect{y}/\vect{x}\}$
denotes the capture-avoiding substitution of $\vect{y}$ for $\vect{x}$ in $Q$.
\end{definition}

\begin{definition}
  The {\em structural congruence} $\equiv$
  between processes \cite{SangiorgiWalker} is the least congruence containing
  alpha-equivalence and satisfying the commutative monoid laws
  (associativity, commutativity and $\pzero$ as identity) for parallel
  composition $|$.
\end{definition}

Rewrite rules
\[\begin{array}{rl}
  d(a,b,c) | m(a,x) & \red m(b,x) | m(c,x) \\
  k(a) | m(a,x) & \red 0 \\
  fw(a,b) | m(a,x) & \red m(b,x) \\
\end{array} \quad \quad
\begin{array}{rl}
  br(a,b) | m(a,x) & \red fw(b,x) \\
  bl(a,b) | m(a,x) & \red fw(x,b) \\
  s(a,b,c) | m(a,x) & \red fw(b,c)
\end{array}\]
\[\begin{array}{rl}
  !P & \red P|!P \\
\end{array}\]
\begin{mathpar}
  \inferrule* {{P} \red {P}'} {{{P} | {Q}} \red {{P}' | {Q}}}
  \and
  \inferrule* {{{P} \scong {P}'} \andalso {{P}' \red {Q}'} \andalso {{Q}' \scong {Q}}}{{P} \red {Q}}
\end{mathpar}

\subsection{RHO combinator calculus}
The {\pic} is not a closed theory, but rather a theory dependent upon
some theory of names. Taking an operational view, one may think of the
{\pic} as a procedure that when handed a theory of names provides a
theory of processes that communicate over those names. This openness
of the theory has been exploited in {\pic} implementations like the
execution engine in Microsoft's Biztalk \cite{biztalk}, where an
ancillary binding language provides a means of specifying a `theory'
of names: {\em e.g.}, names may be TCP/IP ports, or URLs, or object
references, {\em etc.}  But foundationally, one might ask if there is
a closed theory of processes, {\em i.e.} one in which the theory of
names arises from and is wholly determined by the theory of
processes. Meredith and Radestock have shown that this is not only
possible, but results in a calculus that enjoys both the features of
concurrency and meta-programming
\cite{DBLP:journals/entcs/MeredithR05}. The key idea is to provide the
ability to quote processes, effectively reifying them as names, and to
unquote the, effectively reflecting names (which are quoted processes)
back as processes.

The same technique can be applied to Yoshida's combinators. We remove
new names and replication, introduce quoting/unquoting operators,
allow processes in the second argument of a send, and introduce an
extra rewrite governing the interaction between sending and unquoting.

\begin{mathpar}
  \inferrule* [lab=atom] {} { P \bc 0 \;|\; m(a,P) \;|\; d(a,b,c) \;|\; k(a) \;|\; fw(a,b) \;|\; br(a,b) \;|\; bl(a,b) \;|\; s(a,b,c) }
  \and
  \inferrule* [lab=process] {} {\bm \; *a \;|\; P|P}
  \and
  \inferrule* [lab=nominal] {} {a \bc \quotep{P}}
\end{mathpar}

Rewrite rules
\[\begin{array}{rl}
  d(a,b,c) | m(a,P) & \red m(b,P) | m(c,P) \\
  k(a) | m(a,P) & \red 0 \\
  fw(a,b) | m(a,P) & \red m(b,P) \\
\end{array} \quad \quad
\begin{array}{rl}
  br(a,b) | m(a,P) & \red fw(b,@(P)) \\
  bl(a,b) | m(a,P) & \red fw(@(P),b) \\
  s(a,b,c) | m(a,P) & \red fw(b,c) \\
  *(a) | m(a,P) & \red P
\end{array}\]
\begin{mathpar}
  \inferrule* {{P} \red {P}'} {{{P} | {Q}} \red {{P}' | {Q}}}
  \and
  \inferrule* {{{P} \scong {P}'} \andalso {{P}' \red {Q}'} \andalso {{Q}' \scong {Q}}}{{P} \red {Q}}
\end{mathpar}

\begin{definition}
  The {\em structural congruence} $\equiv$
  between processes \cite{SangiorgiWalker} is the least congruence
  satisfying the commutative monoid laws
  (associativity, commutativity and $\pzero$ as identity) for parallel
  composition $|$.
\end{definition}

Note that alpha equivalence is no longer part of structural congruence.  While there is a faithful embedding of Yoshida's combinators into RHO combinators (see below), RHO combinators can see the internal structure of names and distinguish them.

\subsubsection{Implementing replication with reflection}

% D_x = x?(y).(x<*y> | *y)
% 
%       x#y.(x<*y> | *y)
% 1 => vc1c2.(d(xc1c2) | c1#y.m(x*y) | c2#y.*y)
% 7 => vc1c2.(d(xc1c2) | fw(c1x) | c2#y.*y)
% * => vc1c2.(d(xc1c2) | fw(c1x) | *c2)
% 
% 
% 
% vc1c2.(d(xc1c2) | fw(c1x) | *c2) | m(xP)
% => vc1c2.(d(xc1c2) | fw(c1x) | *c2 | m(xP))
% => vc1c2.(d(xc1c2) | m(xP) | fw(c1x) | *c2)
% => vc1c2.(m(c1P) | m(c2P) | fw(c1x) | *c2)
% => vc1c2.(m(xP) | m(c2P) | *c2)
% => vc1c2.(m(xP) | P)
% 
% !_x P = m(x(D_x | P)) | D_x
% = vc1c2.(d(xc1c2) | fw(c1x) | *c2 | m(x(D_x | P)))
% = vc1c2.(m(c1(D_x | P)) | m(c2(D_x | P)) | fw(c1x) | *c2 | m(x(D_x | P)))
% = vc1c2.(m(x(D_x | P)) | m(c2(D_x | P)) | *c2)
% = vc1c2.(m(x(D_x | P)) | D_x | P)
% = m(x(D_x | P)) | D_x | P
As mentioned before, it is known that replication (and hence
recursion) can be implemented in a higher-order process algebra
\cite{SangiorgiWalker}. As our first example of calculation with the
machinery thus far presented we give the construction explicitly in
the RHO combinator calculus.

\begin{definition}[Replication]
  $D(x,v,w) := (d(x,v,w) | fw(v,x) | {*}(w))$
\end{definition}
\[\begin{array}{rl}
  !_{(x,v,w)} P &= m(x,D(x,v,w) \; |\; P) \; |\; D(x,v,w) \\
        &= d(x,v,w) \; |\; fw(v,x) \; |\; {*}(w) \; |\; m(x,D(x,v,w) \; |\; P) \\
        &\red m(v,D(x,v,w) \; |\; P) \; |\; m(w,D(x,v,w) \; |\; P) \; |\; fw(v,x) \; |\; {*}(w) \; |\; m(x,D(x,v,w) \; |\; P) \\
        &\red m(x,D(x,v,w) \; |\; P) \; |\; m(w,D(x,v,w) \; |\; P) \; |\; {*}(w) \\
        &\red m(x,D(x,v,w) \; |\; P) \; |\; D(x,v,w) \; |\; P
\end{array}\]

Of course, this encoding, as an implementation, runs away, unfolding
$\bangp{P}$ eagerly. It is possible to obtain a lazier and more
implementable replication operator, restricted to the image of
input-guarded processes. The reader familiar with the
$\lambda$-calculus will have noticed the similarity between $D$ and
the ``paradoxical'' or ``fixed point'' combinator $Y$.

\subsubsection{Implementing new names with reflection}

Here we provide an encoding of Yoshida's combinator calculus into the
RHO combinator calculus. Since all names are global in the RHO
combinator calculus, we encounter a small complication in the
treatment of free names at the outset. There are several ways to
handle this.  One is to insist that the translation be handed a closed
program, one in which all names are bound either by input or by
restriction; this alternative feels inelegant. Another is to provide
an environment, $r : \mathcal{N}_{\pi} \rightarrow \QProc$, for
mapping the free names in a Yoshida process into names in the RHO
combinator calculus. Maintaining the updates to the environment,
however, obscures the simplicity of the translation. We adopt a third
alternative.

To hammer home the point that Yoshida's combinator calculus is
parameterized in a theory of names, we instantiate her calculus with
the names of the RHO combinator calculus. This is no different than
instantiating her calculus using the natural numbers, or the set of URLs as the
set of names. Just as there is no connection between the structure of
these kinds of names and the structure of processes in the {\pic},
there is no connection between the processes quoted in the names used
by the theory and the processes generated by the theory, and we
exploit this fact.

Let $\QProc$ be set of names in the RHO combinator calculus, $\Proc$
be the set of terms of the RHO combinator calculus, and
$\Proc_{\mbox{\tiny Yoshida}}$ be the set of terms of her combinator
calculus built using $\QProc$ \emph{as the names}. The translation will be
given in terms of a function \[\meaningof{-}_2( -, - ) : 
    \Proc_{\mbox{\tiny Yoshida}} \times \QProc {\times} \QProc \red \Proc.\] 
The guiding intuition is that we construct alongside the process a distributed memory
allocator, the process' access to which is mediated through the second argument
to the function, called $p$ below. The first argument, called $n$ below, determines the shape of the memory for the given allocator.

Since Yoshida's calculus is parametric in a set of names, we can
choose $\QProc$ for that set.  Given a process $P$ in Yoshida's
calculus, we pick names $n$ and $p$ in the RHO calculus such that $n \neq p$
and both are distinct from the free names of $P$.  Then we define

\begin{equation*}
  \meaningof{P} = \meaningof{P}_2(n, p),
\end{equation*}

Name allocation will make heavy use of the following two name
constructors

\begin{eqnarray*}
  x^l & := & \quotep{b_{l}(x,m(x,*x))} \\
  x^r & := & \quotep{b_{r}(x,m(x,*x))}
\end{eqnarray*}

Note that by construction, $\quotep{P}$ cannot occur as a name in $P$
and hence any name derived from a process that is built using
$\quotep{P}$ cannot occur in $P$. Thus, the effect of the superscripts
$l$ and $r$ on a name $x$ is to construct a name that is guaranteed to
be fresh with respect to the free names of the process being
interpreted. More generally, mentioning a name, say $n$, in the
constructor of a another name, say $n'$, guarantees distinction
between $n$ and $n'$; likewise, mentioning a process, say $P$ in the
constructor of a name, $n$ guarantees $n$ is fresh in $P$. The
particular choices of process constructors used in the name
constructors are not essentially for the purposes of freshness. We
make heavy use of this fact in our interpretation of prefix
elimination.

The interpretation function $\meaningof{-}_2(n, p)$ is straightforward
for all but replication and $\mathsf{new}$.

\begin{eqnarray*}
    \meaningof{\pzero}_2 (n,p)
      & = &
       \pzero \\
    \meaningof{\emph{c}(\vect{a})}_2 (n,p) 
      & = & 
      \emph{c}(\vect{a})\mbox{, where $\emph{c}$ is any combinator but $m$} \\
    \meaningof{m(aP)}_2 (n,p) 
      & = & 
          m(a \meaningof{P}_2 (n,p)) \\
    \meaningof{P \juxtap Q}_2 (n,p) 
      & = & 
    \meaningof{P}_2 (n^l, p^l)
         \juxtap \meaningof{Q}_2 (n^r, p^r) \\ 
\end{eqnarray*}

These latter two forms require extra care. We define them in terms of
a prefix form and then use a version of Yoshida's prefix elimination
to remove the prefix.

\begin{eqnarray*}
    \meaningof{\id{!} P}_2 (n,p)
          & = & \binpar{m(x, \meaningof{P}_3(n^r,p^r))}
                  {\binpar{D(x,v,w)}
                    {\binpar{m(n^r, *n^l)}{m(n^r, *n^l)}}} \\
                  & & \mbox{where } 
                      x = @(\meaningof{P}_2(n,p))^{ll}, 
                      v = @(\meaningof{P}_2(n,p))^{lr}, \mbox{ and }
                      w = @(\meaningof{P}_2(n,p))^{rr} \\
    \meaningof{(\new \; x ) P}_2 (n, p) 
          & = & 
         \meaningof{\prefix{p}{x}{\binpar{\meaningof{P}_2 ( n^l, p^l )}{m(p, *n)}}}_4(n, p)
\end{eqnarray*}

As expected, the interpretation of replication makes use of the $D$
operator defined above. Note that name allocation is intertwined with
prefix and new elimination.
         
\begin{eqnarray*}
  \meaningof{P}_3(n, p) 
    & := & 
      \meaningof{\prefix{n}{n'}{\prefix{p}{p'}{(\binpar{\meaningof{P}_2(n',p')}
        {(\binpar{D(x)}{\binpar{\outputp{n}{n'^l}}{\outputp{p}{p'^l}}})})}}}_4. \\
\end{eqnarray*}

To handle prefix elimination we must import most of Yoshida's
algorithm. The key difference is that we must allocate names that
guarantee freshness relative to the free names of the processes being
translated. In those rules below with a ``where'' clause, the specific
choice of combinators in the names is not so important as mentioning
those names and processes with respect to which the name mush be fresh.
For example, in rule $I$, for prefix to a parallel
composition, we must ensure that $v$ and $w$ are fresh with respect to
the names in $P$ and $Q$, and distinct from each other, and then we
must update both the name allocator for each parallel component and
the channels on which fresh names are communicate (so that there is no
interference between the two components) in the recursive call. 

Because the input to $\meaningof{-}_4$ is already in combinator form,
we do not have to import rules 2 -- 4 of her algorithm. Like her, we
assume the following annotations ($+$ stands for the output and $−$
stands for the input), which denote how each name is used in the rules
of interaction:

\[m(a^{+},v^{\pm});d(a^{−},b^{+},c^{+});k(a^{−});fw(a^{−},b^{+});bl(a^{−}b^{+});br(a^{−}b^{−});s(a^{−}b^{−}c^{+})\]

Note the annotated polarities are preserved by reduction, e.g.
\[\binpar{d(a^{−},b^{+},c^{+})}{m(a^{+},v)} \to \binpar{m(b^{+},v)}{m(b^{+},v)}\]

Similarly, for economy of expression, we emulate Yoshida's use of
$\emph{c}$ to represent any combinator matching the arity
specification. 

\[\begin{array}{llrl}
(I)&  \meaningof{\prefix{p}{x}{\binpar{P}{Q}}}_4(n, q) 
    & := & 
    (d(p,v,w)|\binpar{\meaningof{\prefix{v}{x}{P}}_{4}(n_{1}, q_{1})}{\meaningof{\prefix{w}{x}{Q}}_{4}(n_{2}, q_{2}) } \\
    & & & \mbox{where $v = \quotep{(m(q,\binpar{b_{l}(q,n)}{\binpar{P}{Q}}))}$, $w = \quotep{(m(q,\binpar{b_{r}(q,n)}{\binpar{P}{Q}}))}$,} \\
    & & &\mbox{$n_{1} = \quotep{(\binpar{b_{l}(v,w)}{m(q,m(v,*w))})}$, $n_{2} = \quotep{(\binpar{b_{r}(v,w)}{m(q,m(v,*w))})}$} \\
    & & &\mbox{$q_{1} = \quotep{(\binpar{b_{l}(n_{1},n_{2})}{m(q,m(v,*w))})}$, $q_{2} = \quotep{(\binpar{b_{r}(n_{1},n_{2})}{m(q,m(v,*w))})}$} \\
(V)&  \meaningof{\prefix{p}{x}{\emph{c}(v^{+},w)}}_4(n, q) 
    & := & 
    s(p,a,v)|\emph{c}(a^{+},\vect{w})
    \mbox{, where $a = @(\binpar{m(q,*n)}{\emph{c}(v^{+},\vect{w})})$ and $x \not\in v : \vect{w}$}\\
(VI)&  \meaningof{\prefix{p}{x}{\emph{c}(v^{-},\vect{w})}}_4(n, q) 
    & := & 
    s(p,v,a)|\emph{c}(a^{-},\vect{w})
    \mbox{, where $a = @(m(q,*n)|\emph{c}(v^{-},w))$ and $x \not\in v : \vect{w}$} \\
(VII)&  \meaningof{\prefix{p}{x}{m(v,x)}}_4(n, q) 
    & := & 
    fw(p,v) \\
(VIII)&  \meaningof{\prefix{p}{x}{fw(x,v)}}_4(n, q) 
    & := & 
    b_{l}(p,v) \\
(IX)&  \meaningof{\prefix{p}{x}{fw(v,x)}}_4(n, q) 
    & := & 
    b_{r}(p,v) \\
(X)&  \meaningof{\prefix{p}{x}{\emph{c}(\vect{v},x^{+},\vect{w})}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{\binpar{fw(a,x)}{\emph{c}(\vect{v},a^{+},\vect{w})}}}_4(n', q)\\
    & & & \mbox{where $a = @(\binpar{m(q,*n)}{\emph{c}(\vect{v},x^{+},\vect{w})})$} \mbox{ and $n'= \quotep{(m(a,m(q,*n)))}$} \\
(XI)&  \meaningof{\prefix{p}{x}{\emph{c}(x^{-},\vect{v})}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{\binpar{fw(x,a)}{\emph{c}(a^{-},\vect{v})}}}_4(n', q)\\
    & & & \mbox{where $a = @(\binpar{m(q,*n)}{\emph{c}(x^{-},v)})$} \mbox{ and $n'= \quotep{(m(a,m(q,*n)))}$} \\
(XII)&  \meaningof{\prefix{p}{x}{b_{r}(v,x^{-})}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{(\binpar{d(v,w_{1},w_{2})}{\binpar{s(w_{1},x,w_{3})}{br(w_{2},w_{3})}})}}_{4}(n', q) \\
    & & & \mbox{where $w_{1} = \quotep{(\binpar{b_{l}(q,n)}{m(q,b_{r}(v,x^{-}))})}$, $w_{2} = \quotep{(\binpar{b_{r}(q,n)}{m(q,b_{r}(v,x^{-}))})}$,} \\
    & & & \mbox{$w_{3} = \quotep{(\binpar{b_{l}(p,v)}{m(w_{1},*w_{2}})}$, and $n' = \quotep{(s(w_{1},w_{2},w_{3}))}$} \\
(XIII)&  \meaningof{\prefix{p}{x}{s(v,x^{-},w)}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{(\binpar{s(v,w_{1},w_{2})}{\binpar{m(w_{1},*x)}{bl(w_{2},w)}})}}_{4}(n', q) \\
    & & & \mbox{where $w_{1} = @(\binpar{b_{l}(q,n)}{b_{r}(v,x^{-})})$, $w_{2} = @(\binpar{m(q,*n)}{b_{r}(v,x^{-})})$,} \\
    & & & \mbox{and $n' = \quotep{(m(w_{1},*w_{2}))}$}
\end{array}\]

Note that all $\new$-binding is now interpreted, as in Wischik's
global $\pi$-calculus, as an input \cite{globalpi}.

It is also noteworthy that the translation is dependent on how the
parallel compositions in a process are associated. Different
associations will result in different bindings for $\new$
names. This will not result in different behavior, however:
while the RHO combinators can encode different behaviors depending
on the choice of name, Yoshida's combinators cannot and the
embedding is insensitive to the choice.

\subsubsection{Faithfulness of the translation}

\begin{definition}
An \emph{observation relation}, $\downarrow_{\mathcal N}$, over a set
of names, $\mathcal N$, is the smallest relation satisfying the rules
below.

\infrule[Out-barb]{y \in {\mathcal N}, \; x \nameeq y}
    {m(x-) \downarrow_{\mathcal N} x}

\infrule[Par-barb]{\mbox{$P\downarrow_{\mathcal N} x$ or $Q\downarrow_{\mathcal N} x$}}
    {\binpar{P}{Q} \downarrow_{\mathcal N} x}

We write $P \Downarrow_{\mathcal N} x$ if there is $Q$ such that 
$P \wred Q$ and $Q \downarrow_{\mathcal N} x$.
\end{definition}

This definition is parametric in the the argument accepted in the
second position in the message combinator, $m(x-)$, {\em i.e.} the payload
of the message: in the RHO combinators the payload is a process,
while in Yoshida's the payload is a name. Likewise, because the
definition of barbed bisimulation given below is dependent on the
definition of the observation relation, the definition is really a
template for the notion of bisimulation that must be instantiated to
the kind of payload accepted by the message combinator.

%% Notice that $\prefix{x}{y}{P}$ has no barb.  Indeed, in {\rhoc} as well
%% as other asynchronous calculi, an observer has no direct means to
%% detect if a message sent has been received or not.

\begin{definition}
%\label{def.bbisim}
An  ${\mathcal N}$-\emph{barbed bisimulation} over a set of names, ${\mathcal N}$, is a symmetric binary relation 
${\mathcal S}_{\mathcal N}$ between agents such that $P\rel{S}_{\mathcal N}Q$ implies:
\begin{enumerate}
\item If $P \red P'$ then $Q \wred Q'$ and $P'\rel{S}_{\mathcal N} Q'$.
\item If $P\downarrow_{\mathcal N} x$, then $Q\Downarrow_{\mathcal N} x$.
\end{enumerate}
$P$ is ${\mathcal N}$-barbed bisimilar to $Q$, written
$P \wbbisim_{\mathcal N} Q$, if $P \rel{S}_{\mathcal N} Q$ for some ${\mathcal N}$-barbed bisimulation ${\mathcal S}_{\mathcal N}$.
\end{definition}

\begin{theorem}
  $P \wbbisim_{\pi} Q \iff \ldb P \rdb \wbbisim_{\texttt{FN}(P)} \ldb Q \rdb$.
\end{theorem}

\begin{proof}[Proof sketch]
  The forward direction $\Rightarrow$ is immediate from the definition
  of the translation. The reverse direction is only interesting in the
  case of $!$ and $\mathsf{new}$. In the first case, this is
  exactly why we carried out the replication calculation in more
  detail. In the second case, transitions on $\mathsf{new}$-bound
  names will be in one-to-one correspondence with names provided by
  the name parameters of the translation function. By construction,
  these are not observable by the observation relation.
\end{proof}

\begin{remark}
  In light of this theorem, it is worth pointing out that this version
  of the RHO combinators has no rule for \emph{introducing} terms of
  the form $\dropn{x}$. The $br$ and $bl$ combinators introduce new
  names from processes, but the do not introduce new reflection
  terms. Yet, this calculus suffices to faithfully represent the
  Yoshida combinators. This is because the translation function is
  carefully introducing just those terms, via the $D(x,v,w)$ operator,
  guided by the use of replication in the source to the
  translation. 
\end{remark}

\section{Gph-enriched categories}
Here we review some standard definitions and results in enriched category theory; see \cite{CIS-335497}, \cite{Power99EnrichedLawvereTheories}, \cite{DBLP:journals/acs/LackR11}, and \cite{Trimble} for more details.

A {\bf directed multigraph}, hereafter {\bf graph}, consists of a set $E$ of edges, a set $V$ of vertices, and two functions $s,t\maps E \to V$ picking out the source and target of each edge.  There are no constraints on $E, V, s,$ or $t$, so a graph may have infinitely many vertices, infinitely many edges between any two vertices, and loops.  A {\bf graph homomorphism} from $(E, V, s, t)$ to $(E', V', s', t')$ is a pair of functions $(\epsilon\maps E \to E', \upsilon\maps V \to V')$ such that $\upsilon\circ s = s' \circ \epsilon$ and $\upsilon\circ t = t' \circ \epsilon$.  {\bf Gph} is the category of graphs and graph homomorphisms.  Gph has finite products: the terminal graph is the graph with one vertex and one loop, while the product of two graphs $(E, V, s, t) \times (E', V', s', t')$ is $(E \times E', V \times V', s \times s', t\times t').$

A {\bf Gph-enriched category} is a category where each hom set $\hom(x,y)$ is equipped with a set $E_{x,y}$ and functions $s_{x,y}, t_{x,y}\maps E_{x,y} \to \hom(x,y);$ that is, each hom set is thought of as a set of vertices and is equipped with a set of edges making it into a graph.  A Gph-enriched category has finite products if the underlying category does.

Any category is trivially Gph-enriched by taking the all the sets of edges to be empty.  Given two graph homomorphisms $F, G\maps (E, V, s, t) \to (E', V', s', t'),$ a {\bf graph shift} assigns to each vertex $v$ in $V$ an edge $e'$ in $E'$ such that $s'(e') = F(v)$ and $t'(e') = G(v).$  The category Gph is nontrivially Gph-enriched, making it a cartesian closed category: the objects are graphs, and for any pair of graphs $(G, G')$ we get a graph whose vertices are graph homomorphisms from $G$ to $G'$ and whose edges are graph shifts.

A {\bf Gph-enriched functor} between two Gph-enriched categories $C, D$ is a functor between the underlying categories such that the graph structure on each hom set is preserved, {\em i.e.} the functions between hom sets are graph homomorphisms between the hom graphs.

Let $S$ be a finite set, $\FinSet$ be a skeleton of the category of finite sets and functions between them, and $\FinSet/S$ be the category of functions into $S$ and commuting triangles.  A {\bf multisorted Gph-enriched Lawvere theory}, hereafter {\bf Gph-theory} is a Gph-enriched category with finite products Th equipped with a finite set $S$ of {\bf sorts} and a Gph-enriched functor $\theta\maps \FinSet^{\op}/S \to \Th$ that preserves products strictly.  Any Gph-theory has an underlying multisorted Lawvere theory given by forgetting the edges of each hom graph.

A {\bf model} of a Gph-theory Th is a Gph-enriched functor from Th to Gph that preserves products up to natural isomorphism.  A {\bf homomorphism of models} is a braided Gph-enriched natural transformation between the functors.  Let FPGphCat be the 2-category of small Gph-enriched categories with finite products, product-preserving Gph-functors, and braided Gph-natural transformations.  The forgetful functor $U\maps \FPGphCat[\Th, \Gph] \to \Gph$ that picks out the underlying graph of a model has a left adjoint $L$ that picks out the free model on a graph.

\section{Gph-theories as models of computation}

Lawvere theories and their generalizations are categories with infinitely many objects and morphisms, but most theories of interest are finitely generated.  A presentation of underlying multisorted Lawvere theory of a finitely-generated Gph-theory is a signature for a term calculus, consisting of a set of sorts and a set of term constructors, while the edges in the hom graphs of the theory encode the reduction relation.

Here is a presentation of the SKI combinator calculus as a Gph-theory:
\begin{itemize}
  \item one sort $T$, for terms
  \item term constructors
  \[\begin{array}{rl}
    S&:1 \to T\\
    K&:1 \to T\\
    I&:1 \to T\\
    (-\; -)&: T^2 \to T\\
  \end{array}\]
  \item rewrites
  \[\begin{array}{rl}
    \sigma&:(((S\; x)\; y)\; z) \Rightarrow ((x\; z)\; (y\; z))\\
    \kappa&:((K\; y)\; z) \Rightarrow y\\
    \iota&:(I\; z) \Rightarrow z\\
  \end{array}\]
\end{itemize}
where in the rewrites we have used expressions like $((K\; y)\; z)$ as shorthand for
\[ T\times T \xrightarrow{\tiny\mbox{left}^{-1}} 1\times T \times T \xrightarrow{K \times T \times T} T\times T \times T \xrightarrow{(-\;-)\times T} T\times T \xrightarrow{(-\;-)} T. \]

A model $M$ of this Gph-theory in Gph picks out a graph $M(T)$ of terms and rewrites.  It picks out three special vertices $S,K,$ and $I$ of $M(T)$; it equips $M(T)$ with a graph homomorphism from $M(T)^2$ to $M(T)$ that says for every pair of vertices $(u,v),$ there is a vertex $(u\;v)$, and similarly for edges; and it equips $M(T)$ with graph shifts asserting the existence of an edge out of a reducible expression to the term it reduces to.

That this Gph-theory captures the semantics of the SKI calculus is almost definitional: there is an edge in the free model on the empty graph if and only if the source vertex is reducible to the target vertex.  

It is straightforward to verify that Gph-theories suffice to capture the operational semantics of any calculus where every context is a reduction context.  This restriction on reduction contexts is a consequence of the fact that models map term constructors to graph homomorphisms: given a model $M$, a graph homomorphism $F\maps M(T) \to M(T)$, and an edge $e\maps t_1 \to t_2,$ there is necessarily an edge $F(e)\maps F(t_1) \to F(t_2).$

\section{Gph-theory for the RHO combinators}
The RHO combinators above also have a presentation as a Gph-theory:
\begin{itemize}
  \item Sorts $N, T$
  \item Term constructors
    \[\begin{array}{rl}
      0 &: 1 \to T \\
      k &: N \to T \\
      m &: N \times T \to T \\
      fw,br,bl &: N^2 \to T \\
    \end{array} \quad \quad
    \begin{array}{rl}
      s &: N^3 \to T \\
      | &: T^2 \to T \\
      * &: N \to T \\
      @ &: T \to N \\
    \end{array}\]
  \item Structural equivalence
    \[\begin{array}{rl}
      P | 0 & = P \\
      P | Q & = Q | P \\
      ((P | Q) | R) & = (P | (Q | R)) \\
    \end{array}\]
  \item Rewrite rules
    \[\begin{array}{rl}
      d(a,b,c) | m(a,P) & \Rightarrow m(b,P) | m(c,P) \\
      k(a,) | m(a,P) & \Rightarrow 0 \\
      fw(a,b) | m(a,P) & \Rightarrow m(b,P) \\
      br(a,b) | m(a,P) & \Rightarrow fw(b,@(P)) \\
    \end{array} \quad \quad
    \begin{array}{rl}
      bl(a,b) | m(a,P) & \Rightarrow fw(@(P),b) \\
      s(a,b,c) | m(a,P) & \Rightarrow fw(b,c) \\
      *a | m(a,P) & \Rightarrow P \\
      *(@(P)) & \Rightarrow P \\
    \end{array}\]
\end{itemize}

\section{Conclusion and future work}
We have shown how to construct a concurrent higher-order combinator
calculus that uses reflection to avoid the necessity for new and bound
names.  Yoshida's combinators, and therefore the asynchronous {\pic}
have a faithful embedding into the calculus.  We have also given a
Gph-theory that captures the calculus' operational semantics.  Just as
the S and K combinators correspond to the axioms of intuitionistic
logic, we anticipate that the combinators of this calculus will be
typable and will correspond to axioms in a logic of concurrency.

\bibliographystyle{amsplain}
\bibliography{rhocomb}
\end{document}
