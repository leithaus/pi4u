\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{MeMo 2017}
\usepackage{microtype}
\usepackage{bussproofs}
\usepackage{stmaryrd}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{graphicx}

\newtheorem{theorem}{Theorem}
\newtheorem{proof}{Proof}

\newcommand{\new}{\mathsf{new}}
\newcommand{\for}{\mathrm{for\ }}
\newcommand{\yield}{\mathrm{yield\ }}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\interp}[1]{\llbracket #1 \rrbracket}
\newcommand{\interpp}[1]{\{\!| #1 |\!\}}
\newcommand{\from}{\leftarrow}
\newcommand{\maps}{\colon}
\newcommand{\End}{\mathrm{End}}
\newcommand{\Th}{\mathrm{Th}}
\newcommand{\Gph}{\mathrm{Gph}}
\newcommand{\FinSet}{\mathrm{FinSet}}
\newcommand{\FPGphCat}{\mathrm{FPGphCat}}
\newcommand{\Set}{\mathrm{Set}}
\newcommand{\Cat}{\mathrm{Cat}}
\newcommand{\Calc}{\mathrm{Calc}}
\newcommand{\Mon}{\mathrm{Mon}}
\newcommand{\op}{\mathrm{op}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\pic}{$\pi\mbox{-calculus}$\xspace}
\newcommand{\lac}{$\lambda\mbox{-calculus}$\xspace}
\newcommand{\entails}{\vdash}
\newcommand{\imp}{\mathop{\mbox{\reflectbox{$\vDash$}}}}
\newcommand{\edge}{\mathrm{edge}}

\def\titlerunning{How to derive a type system from a term calculus, a collection, and a distributive law}
\def\authorrunning{M.\ Stay and L.\ G.\ Meredith}

\begin{document}
\EnableBpAbbreviations
\title{How to derive a type system from a term calculus, a collection, and a distributive law}
\author{Michael Stay
  \institute{Pyrofex Corp.}
  \email{stay@pyrofex.net}
  \and
  L.G. Meredith
  \institute{RChain Cooperative}
  \email{greg@rchain.coop}
}
\maketitle
\begin{abstract}
  \noindent We present an algorithm for generating a powerful type system automatically, given a term calculus, a collection monad, and a distributive law.  The algorithm is practically forced on us by the need to reconcile 1) the principle from the Curry-Howard-Lambek isomorphism that types correspond to predicates and programs correspond to constructive proofs and 2) the principle from realizability that predicates about computable structures correspond to the collection of terms that satisfy them.  The modality-free fragment of the type system is sound and complete by construction.  
  
  We can write down grammars for term calculi and for collections.  By combining the two grammars and using a distributive law, we get a language for describing collections of terms.  We can then add other features like modalities and recursion.  The resulting construction is a Caires-style spatial-behavioral type system.
  
  Lambek's contribution to the isomorphism was to show that types and and lambda terms modulo rewrites give cartesian closed categories.  Our generated type system gives rise to a category with predicates as objects and witnesses of typing judgements as morphisms; it comes equipped with dinatural transformations for each inference rule, which in turn are generated by the rewrites of the calculus.  By construction, we get a cut-elimination theorem.  We show that we can recover Lambek's denotational semantics of \lac as a special case, and also that arrow types arise as a special case of a generalized possibility modality.
\end{abstract}

\EnableBpAbbreviations

\section{Introduction}

Many widely-used programming languages in production today have weak static typing or none at all.  Whatever its merits, dynamic typing makes it hard to detect type errors before the users of the program do.  Microsoft's TypeScript \cite{TypeScript},
% https://www.typescriptlang.org/ 
Facebook's Flow \cite{Flow}, 
% https://flow.org/
and Google's Closure Compiler \cite{Closure}
% https://developers.google.com/closure/compiler/
are all massive projects trying to retrofit static types onto JavaScript; each company has found that static types are necessary for reliability in production.  Similarly, the MyPy project \cite{MyPy}
% http://mypy-lang.org/
is trying to retrofit static types to Python.

Every type system of which we're aware was created by hand, and type systems are not always easy to define.  Milner \cite{Milner}
% Milner pi calculus tutorial
was only able to give a simple sorting to the \pic.  It took fourteen years to advance the field to the point that Caires was able to present a spatial-behavioral type system powerful enough to reason about the behavior of \pic terms rather than just the type of data sent on the channels \cite{Caires}.
% Behavioral and Spatial Observations in a Logic for the Ï€-Calculus

In this paper, we will give an algorithm for generating a spatial-behavioral type system automatically from a presentation of the operational semantics of a term calculus and a grammar for a collection monad.  The resulting type system is sound and complete by construction.  The algorithm is practically forced on us when we consider the two requirements that types correspond to predicates and that predicates be represented by collections of terms.

Given a presentation of a term calculus, we can construct a graph $G$ whose vertices are terms of the calculus and whose edges are rewrites.  If we add ``do-nothing'' rewrites to each vertex, we can describe the whole graph just in terms of its edges.  The Curry-Howard-Lambek isomorphism famously says that types correspond to predicates.  The isomorphism works for predicates on any set, but when we consider predicates on the set of edges in $G,$ something magical happens: we can think of types as being inhabited by the collection of edges that satisfy the predicate---in other words, types describe the behavior of programs.

Predicates need to talk about terms and rewrites as well as be able to assemble them together into a collection.  Usually we take the collection to be sets of edges because we want to consider subgraphs of $G,$ which form a Heyting algebra.  Since we have a grammar for the edges of $G$ and a grammar for Heyting algebras, we can consider the sum of the grammars to be a language for expressing predicates.

To this language we can add modalities.  If $\phi$ is a predicate that picks out some subgraph of $G,$ we can define $\diamond\phi$ to be a predicate satisfied by the set of terms that possibly reduce to a term in $\phi;$ similarly, we can define $\box\phi$ to be a predicate satisfied by the set of terms that necessarily reduce to a term in $\phi.$  We'll show later that a generalization of the ``possibly'' modality that is parametric in a two-hole term context gives rise both to the familiar arrow types of applicative calculi as well as Caires' rely-guarantee modality.

Denotational semantics asks what function a term denotes, and works really well for functional programming languages.  The actual process of computation is largely ignored: it doesn't matter {\em how} you compute the function, just {\em what} the function is.  Denotational semantics gets a lot harder once we move away from functional programming languages.  Modern programs run on multiple computers at the same time, and each computer has several cores. The computers are connected by networks that can mix up the order in which messages are received.  A program may run perfectly by itself, but deadlock when you run it in parallel with another copy of itself.  The notion of ``composition'' begins to change, too: we run programs in parallel with each other and let them interact by passing messages back and forth, not simply by feeding the output of one function into the input of another.  All of this makes it hard to think of such programs as functions.

Operational semantics is the other end of the spectrum, concerned with the rules by which the state of a computer changes.  Whereas denotational semantics is inspired by Church and the \lac, operational semantics is inspired by Turing and his machines: every virtual machine is an executable spec for an operational semantics.  Operational semantics has been criticized by advocates of denotational semantics as being completely ad-hoc and hard to reason about.  In response, the operational semantics community developed tools like K framework \cite{kframework} and Maude \cite{Maude}, principled approaches that make reasoning about operational semantics much easier.

Categorical semantics has traditionally been very function-oriented: Lambek's contribution \cite{Lambek} to the Curry-Howard-Lambek isomorphism was to show how to construct a cartesian closed category of types and equivalence classes of lambda terms with one free variable, and then assign denotations to the types and terms with a cartesian closed functor into Set.  Despite this tradition, categorical semantics generalizes very easily.  For example, when we generalize from the cartesian product to an arbitrary tensor product, we get symmetric monoidal closed categories, whose internal language is {\em linear} \lac.  Linear \lac has models in the category Hilb of Hilbert spaces and linear transformations, so we get a notion of a quantum programming language.

Generalizing from categories to enriched categories lets us use Lambek's techniques to capture information about operational semantics; we enrich over graphs, so rather than forming a mere set of terms, we can form a graph of terms and rewrites.  Our generated type system gives rise to a category with predicates as objects and witnesses of typing judgements as morphisms; the category comes equipped with dinatural transformations for each inference rule, which in turn are generated by the rewrites in the calculus.  By construction, we get a cut-elimination theorem.  Given such a categorical representation of the operational semantics of a functional programming language, we can throw away information about how the function is computed and, like Lambek, look for denotational semantics in Set; but given a categorical representation of the operational semantics of a nondeterministic, concurrent programming language like \pic, we can still look at functors to categories that preserve the relevant structure.

\section {Operational semantics}

To talk about the operational semantics of a programming language, there are five things we need to define.

First, we have to describe the layout of the state of the computer. For each kind of data that goes into a description of the state, we have a ``sort''.  If we're using a programming language like \lac, we have a sort for variables and a sort for terms, and the term is the entire state of the computer.  If we're using a Turing machine, there are more parts: the tape, the state transition table, the current state, and the position of the read/write head on the tape.  If we're using a modern language like C, the state is very complex: K framework's formalization of C has hundreds of sorts.

Second, we have to build up the state itself using ``term constructors''.  For example, in \lac, we start with variables and use abstraction and application to build up terms.

Third, we say what rearrangements of the state we're going to ignore; this is called ``structural congruence''.  In \lac, we say that two terms are the same if they only differ in the choice of bound variables.  In \pic, it doesn't matter in what order we list the processes that are all running at the same time.

Fourth, we give ``reduction rules'' describing how the state is allowed to change.  In \lac, the state only changes via $\beta$-reduction, substituting the argument of a function for the bound variable.  In a Turing machine, each state leads to one of five others (change the bit to 0 or 1, then move left or right; or halt).  In \pic, there may be more than one transition possible out of a particular state: if a process is listening on a channel and there are two messages, then either message may be processed first. Computational complexity theory is all about how many steps it takes to compute a result, so we do not have equations between sequences of rewrites; in fact, dynamic programming problems like finding the optimal order in which to multiply a sequence of matrices are often about choosing which of several paths that compute the same result is shortest.

Finally, the reduction rules themselves may only apply in certain ``contexts''; for example, in all modern programming languages based on the \lac, no reductions happen under an abstraction. That is, even if a term $t$ reduces to $t'$, it is never the case that $\lambda x.t$ reduces to $\lambda x.t'$.  The resulting normal form is
called ``weak head normal form'' (WHNF).

Here's an example from Boudol's paper ``The $\pi$-calculus in direct style'' \cite{Boudol}.
% http://www-sop.inria.fr/meije/personnel/Gerard.Boudol/popl97-abstract.html
There are two sorts: $x$ or $z$ for variables and $L$ or $N$ for
terms.  The first line, labeled ``syntax'', defines four term constructors.  There are equations for structural congruence, and there are two reduction rules followed by the contexts in which the rules apply: 
\newcommand{\deff}{\mathop{\mbox{def}}}
\newcommand{\inn}{\mathop{\mbox{in}}}
\[\small
\begin{array}{lr}
  L ::= x \quad|\quad \lambda xL \quad|\quad (Lx) \quad|\quad (\deff x = L \inn L) & \mbox{syntax}\\
  x \ne z \Rightarrow (\deff x = N \inn L)z \equiv (\deff x = N \inn Lz) & \mbox{structural congruence}\\
  (\lambda xL)z \to [z/x]L & \mbox{reduction} \\
  (\deff \cdots x = L \cdots \inn xy_1\cdots y_n) \to (\deff \cdots x = L \cdots \inn Ly_1\cdots y_n) \\
  L \to L' \Rightarrow (Lz) \to (L'z) & \mbox{context rules} \\
  L \to L' \Rightarrow (\deff x=N \inn L)
\to (\deff x=N \inn L')\\
  L \to L' \& N \equiv L \Rightarrow N \to L'
\end{array}
\]

\section{Categorical semantics}

In Lawvere's seminal 1963 thesis \cite{Lawvere}, he showed that categories with finite products suffice to model all of universal algebra.  If a mathematical gadget can be described as sets equipped with functions satisfying axioms, there is a finite-products category Th such that all gadget arise as product-preserving functors from Th to Set, and each finite-products category defines a gadget.  For example, the Lawvere theory of monoids is the free finite products category on
\begin{itemize}
  \item an object M and
  \item morphisms 
  \begin{itemize}
    \item $\cdot\maps M^2 \to M$ and
    \item $e\maps 1 \to M$ modulo the following equations:
  \end{itemize}
  \item $\forall xyz.(x\cdot y)\cdot z = x\cdot(y\cdot z),$ {\em i.e.} multiplication is associative, and
  \item $\forall x.e \cdot x = x\cdot e = x,$ {\em i.e.} multiplication is unital.
\end{itemize}
This kind of presentation should look very familiar to programmers; compare this Agda definition of a monoid:
\begin{verbatim}
  data Monoid (M : Set)(Eq : Equivalence M) : Set where
    monoid :
      (_*_ : M -> M -> M)
      (e   : M)
      (assoc : Associative Eq _*_)
      (leftId : LeftIdentity Eq e _*_)
      (rightId : RightIdentity Eq e _*_) ->
      Monoid M Eq
\end{verbatim}

A model of a Lawvere theory (in the category Set unless otherwise specified) is a product-preserving functor from the theory to Set.  A model of the theory above maps $M$ to a set and $\cdot$ and $e$ to functions that satisfy the equations---that is, it picks out a monoid.  All monoids arise as such functors. Monoids, groups, rings, natural numbers, and graphs are all examples of gadgets that can be defined in this way; fields are a notable exception.  

For those readers familiar with defining data structures with monads, just know that Lawvere theories correspond to finitary monads on Set.  Given some algebraic gadget, we can forget all the extra structure and just look at the underlying set; Lawvere proved that this forgetful functor has a left adjoint, the free gadget on a set.  The free functor followed by the forgetful functor gives a finitary monad on Set.  Lawvere also proved that the opposite of the category of free finitely-generated algebras of the monad is equivalent to the original Lawvere theory.

A ``Gph-theory'', defined below, is a Lawvere theory in which we can specify directed edges between morphisms without having to declare them equal; this lets us encode the notion of a reduction or rewrite between terms.  We can think of a presentation of a Gph-theory as a specification file for a toy version of K framework---in fact, we are working on implementing our algorithm as a transformation of actual K framework specifications.

Gph-theories, by default, have models not in the category Set, but rather in the category Gph of graphs and graph homomorphisms.  A model of a Gph-theory of a term calculus assigns to the distinguished sort an infinite graph whose vertices are all the terms of the calculus and whose edges are rewrites between them.  The model assigns a graph homomorphism to each morphism in the theory; we can think of most of the morphisms as $n\mbox{-}$ary term constructors.  The graph homomorphism corresponding to an $n\mbox{-}$ary term constructor takes an $n\mbox{-}$tuple of vertices/terms and maps it to a single vertex, the term context with its holes filled by the elements of the tuple.  It also maps edges to rewrites in that context.

As noted in the previous section, not every term context is a reduction context: when reducing lambda terms to WHNF, the fact that some term $t$ reduces to $t'$ does not mean that $\lambda x.t$ reduces to $\lambda x.t'.$  However, if we model a term constructor by a graph homomorphism $K,$ any edge $e\maps t \to t'$ maps to another edge $Ke\maps Kt \to Kt';$ therefore, Gph-enriched Lawvere theories insist that reductions may occur in any context.  We can simulate more restrictive reduction contexts by introducing morphisms for denoting reduction contexts and then using those morphisms in the rewrite rules; see the example in section \ref{skexample}.  The models of such a theory may contain terms in which reduction contexts are mislabeled, but if the equations and the rewrite rules preserve proper labeling, then all reductions of a properly labeled term will also be properly labeled.

We should say something about binders.  Reasoning about languages with binders is a hard-enough problem that it was the focus of the 2005 PoplMark challenge \cite{PoplMark}.
\begin{quote}
  The problem of representing and reasoning about inductively-defined structures with binders is central to the PoplMark challenges. Representing binders has been recognized as crucial by the theorem proving community, and many different solutions to this problem have been proposed. In our (still limited) experience, none emerge as clear winners.
\end{quote}
%https://link.springer.com/chapter/10.1007/11541868_4
More recently, Gabbay and Pitts \cite{GabbayPitts} developed the theory of nominal sets.  It is our impression that nearly everyone now agrees that using nominal sets to formally model binders is the way forward.  Clouston \cite{Clouston}
% http://cs.au.dk/~ranald/Clouston_WoLLIC.pdf
defined nominal Lawvere theories.  We anticipate that enriching nominal Lawvere theories in Gph will allow us to model the operational semantics of languages with binders, but in this paper, we restrict ourselves to languages without.  This is not a severe restriction: we can eliminate abstractions from applicative calculi like \lac by using $S$ and $K$ combinators; in a similar way, we can eliminate input prefixes from concurrent calculi like \pic using Yoshida's combinators \cite{Yoshida} and eliminate uses of the ``new name'' binder using the reflective techniques of Meredith and Radestock \cite{MeredithRadestock}.
%  http://www.sciencedirect.com/science/article/pii/S1571066105051893

\subsection{Gph-theories}

This section relies on standard definitions from and results of enriched category theory; the reader unfamiliar with the subject may find a review in appendix \ref{GphReview}.

A {\bf multisorted Gph-enriched Lawvere theory}, hereafter {\bf Gph-theory} is a Gph-enriched category with finite products Th equipped with a finite set $S$ of {\bf sorts} and a Gph-enriched functor $\theta\maps \FinSet^{\op}/S \to \Th$ that preserves products strictly.  When modeling term calculi, we assume that there's a distinguished sort $T$ that represents the state of the entire computer.  Any Gph-theory has an underlying multisorted Lawvere theory given by forgetting the edges of each hom graph.

A {\bf model} of a Gph-theory Th is a Gph-enriched functor from Th to Gph that preserves products up to natural isomorphism.  A {\bf homomorphism of models} is a monoidal Gph-enriched natural transformation between the functors.  Let FPGphCat be the 2-category of small Gph-enriched categories with finite products, product-preserving Gph-functors, and monoidal Gph-natural transformations.  The forgetful functor $U\maps \FPGphCat[\Th, \Gph] \to \Gph$ that picks out the underlying graph of a model has a left adjoint that picks out the free model on a graph.

Gph-enriched categories are part of a spectrum of 2-category-like structures.  A strict 2-category is a category enriched over Cat with its usual product.  Sesquicategories are categories enriched over Cat with the ``funny'' tensor product \cite{Lack2010}; a sesquicategory can be thought of as a generalized 2-category where the interchange law does not hold.  A Gph-enriched category can be thought of as a generalized sesquicategory where 2-morphisms (now edges) cannot be composed.  Any strict 2-category has an underlying sesquicategory, and any sesquicategory has an underlying Gph-enriched category; these forgetful functors have left adjoints.

\subsubsection{Example: SK calculus}
\label{skexample}
The SK calculus was invented by Moses Sch\"onfinkel, a member of Hilbert's group at Gottingen, to eliminate bound variables in logical statements involving quantifiers.  Years later, Curry realized that the types of Sch\"onfinkel's $S$ and $K$ combinators were the axiom schemata in the Hilbert-style deductive system for positive implicational logic.

Here's a presentation of the Gph-theory for the SK calculus with reduction to WHNF.  We have modeled reduction contexts with a morphism $R.$  One can prove that this Gph-theory preserves proper labeling of reduction contexts by noting that the equations and rewrite rules preserve the number of occurrences of $R$ in a term as well as guaranteeing that if an $R$ appears on the left-hand side of an application, it will remain on the left.  Therefore, given a term $t$ with no occurrences of $R,$ the term $Rt$ reduces to $Rt',$ where $t'$ is the WHNF of $t.$

\begin{itemize}
  \item objects
    \begin{itemize}
      \item the distinguished sort $T,$ for terms
    \end{itemize}
  \item morphisms
    \begin{itemize}
      \item $S\maps 1 \to T$
      \item $K\maps 1 \to T$
      \item $(-\; -)\maps T^2 \to T$
      \item $R\maps T \to T,$ for reduction contexts
    \end{itemize}
  \item equations
    \begin{itemize}
      \item $\forall xy.R(x\; y) = (Rx\; y),$ {\em i.e.} to reduce a term, we reduce the applicand but not the term it's applied to
    \end{itemize}
  \item edges
    \begin{itemize}
      \item $\sigma\maps (((RS\; x)\; y)\; z) \Rightarrow ((Rx\; z)\; (y\; z))$
      \item $\kappa\maps ((RK\; x)\; z) \Rightarrow Rx$
    \end{itemize}
\end{itemize}


\subsection{Lawvere theories of collections}

By a collection, we mean a single-sorted Lawvere theory whose models have an underlying monoid.  In Haskell terminology, a collection is a MonadPlus.  Typically, we want our predicates to characterize subgraphs of the graph of all terms and rewrites so we use the Lawvere theory of Heyting algebras.  In order to distinguish implication from an edge, we will denote implication with $\imp.$
\begin{itemize}
  \item objects
    \begin{itemize}
      \item $T$
    \end{itemize}
  \item morphisms
    \begin{itemize}
      \item $\top, \bot\maps 1 \to T$
      \item $\land, \lor, \imp\maps T^2 \to T$
    \end{itemize}
  \item equations
    \begin{itemize}
      \item conjunction and disjunction are associative, commutative, and unital
      \item $\forall a.a \imp a = \top$
      \item $\forall ab.a \land (a \imp b) = a \land b$
      \item $\forall ab.b \land (a \imp b) = b$
      \item $\forall abc.a \imp (b \land c) = (a \imp b) \land (a \imp c)$
    \end{itemize}
\end{itemize}

\subsection{Lawvere theories of edges}

A reflexive graph has a distinguished self-loop on each vertex, so we can capture all the information about a subgraph just by listing its edges.  Given a Gph-theory Th, define the Lawvere theory Edge(Th) to be the coproduct of the underlying Lawvere theory of Th and, for each edge $e\maps X \Rightarrow Y \maps A \to B,$ a generating morphism $e\maps A \to B.$  For example, Edge(SK) has a presentation

\begin{itemize}
  \item objects
    \begin{itemize}
      \item $T$
    \end{itemize}
  \item morphisms
    \begin{itemize}
      \item $S\maps 1 \to T$
      \item $K\maps 1 \to T$
      \item $(-\; -)\maps T^2 \to T$
      \item $R\maps T \to T$
      \item $\sigma\maps T^3 \to T$
      \item $\kappa\maps T^2 \to T$
    \end{itemize}
  \item equations
    \begin{itemize}
      \item $R(x\; y) = (Rx\; y)$
    \end{itemize}
\end{itemize}

Morphisms out of the terminal object in Edge(SK) denote edges in the graph of SK terms and rewrites.  For example, the morphism 
\[\sigma \circ (K \times K \times S)\maps 1 \to T\]
in Edge(SK) denotes the edge
\[\sigma_{K,K,S}\maps (((RS\; K)\; K)\; S) \to ((RK\; S)\; (K\; S))\]
in the graph of SK terms and rewrites.

\subsection{Lawvere theories of predicates}

In this subsection we combine the results of the previous two subsections to describe a Lawvere theory of predicates that is parametric in a theory of edges, a theory of collections, and a distributive law between the compositions of the corresponding monads.  

There's an obvious way to take the union of two multisorted Lawvere theories: we simply take the disjoint union of the sets of sorts, take all the morphisms, and take all the equations.  We can also quotient a multisorted Lawvere theory by an equivalence that identifies two sorts and get a theory that describes certain degenerate models of the original theory.

Given a Lawvere theory of a collection Coll, we define the Lawvere theory Pred(Th, Coll) to be the union of Edge(Th) and Coll, modulo identifying the distinguished sort from Edge(Th) with the single sort of the theory of collections.  The resulting terms describe subgraphs of the graph of all terms and rewrites.  For example, $(S\; \top)$ describes the subgraph of all terms that are an application of $S$ to some other term and all rewrites between them; similarly, $\sigma(\top, \top, \top)$ describes the subgraph of all terms in which $S$ is applied to three terms in a reduction context and the subsequent reductions.

\subsection{Distributive laws}

We want to interpret a predicate as a collection of edges.  To define the interpretation of a predicate, we need a distributive law.  A predicate like $(S\; \top)$ involves arbitrary switching between term constructors in Edge(Th) and term constructors in Coll.  We want to move all the term constructors for collections to the outside so that we get a collection of edges.  Thinking of Edge(Th) and Coll as finitary monads, we choose a natural transformation
\[ \delta\maps \mbox{Edge(Th)}\circ\mbox{Coll} \Rightarrow \mbox{Coll}\circ\mbox{Edge(Th)} \]
that preserves the monad operations.

Such a natural transformation may not exist.  For example, if we use multisets of rewrites of SK terms rather than mere sets, there's no distributive law we can use, because $S$ and $K$ duplicate and delete their arguments, respectively.  We get different numbers of elements when we take the top right path and the bottom left path around the square that's supposed to commute.  We can use multisets, however, if we use linear combinators like $B,C,$ and $I.$

\section{Logic}
\subsection{Spatial types}
Recall that Lambek defined a cartesian closed category by taking types as objects and equivalence classes of lambda terms with one free variable as morphisms.  The equivalence identified lambda terms that varied only in the choice of free variable ($\alpha\mbox{-}$equivalence); it identified terms $t$ with $\lambda x.(t\; x),$ where $x$ was not free in $t$ ($\eta\mbox{-}$equivalence or extensionality); and if some term $t$ reduced to a term $u$, it identified $t$ and $u$ ($\beta\mbox{-}$equivalence). 

The Gph-theory Th of a term calculus has a sub-Gph-encriched category $\End_\Th(T)$ of endomorphisms on its distinguished object $T.$  The morphisms are one-hole term contexts, and the edges are rewrites of contexts.  $\End_\Th(T)$ is very nearly an ``untyped'' version of Lambek's construction, but it retains the edges instead of identifying all the terms in a connected component.  If we mod out $\End_\Th(T)$ by edges and Curry's equations for extensionality 
\begin{itemize}
  \item $K = S(S(KS)(S(KK)K))(K(SKK))$
  \item $S = S(S(KS)(S(K(S(KS)))(S(K(S(KK)))S)))(K(K(SKK)))$
  \item $S(KK) = S(S(KS)(S(KK)(S(KS)K)))(KK)$
  \item $S(KS)(S(KK)) = S(KK)(S(S(KS)(S(KK)(SKK)))(K(SKK)))$
  \item $S(K(S(KS)))(S(KS)(S(KS)))$ \\ $= S(S(KS)(S(KK)(S(KS)(S(K(S(KS)))S))))(KS)$
\end{itemize}
we get a cartesian closed category, the untyped SK calculus.  For concurrent calculi like \pic, we don't want to mod out by edges.

We can define an equivalent Gph-enriched category Spatial(Th, Coll) whose objects are predicates, whose morphisms are one-hole term contexts, and whose edges are context rewrites.  Putting a predicate in a one-hole term context gives a new predicate, so for every predicate $X$ and morphism $t\maps T \to T$ in $\End_\Th(T)$ we get a morphism $\tilde{t}_X\maps X \to t[X].$  Similarly, since putting an edge in a one-hole term context gives a new edge, for every predicate $X$ and edge $e_X\maps t_X \to t'_X,$ we get an edge $\tilde{e}_X\maps \tilde{t}_X \to \tilde{t'}_X.$  The forgetful functor that maps every predicate $X$ to the unique object in $\End_\Th(T)$ is half of the equivalence; the other half maps the unique object to any one predicate $X.$  We can build a system of logic in this scenario, though it is necessarily somewhat degenerate.  

Each one-hole term context $\tilde{t}$ is a Gph-enriched endofunctor on Spatial(Th, Coll).  We compose with the Yoneda functor to think of it as a profunctor; the profunctor represents a typing judgement $X \entails t[]\maps t[X].$  The monoidal unit $\bot$ from the collection monad gives an inclusion Gph-enriched endofunctor representing a subtyping judgement $\bot \subseteq X,$ and the monoidal multiplication $\lor$ gives an inclusion Gph-enriched endofunctor representing a subtyping judgement $X \subseteq X \lor Y.$

Each term constructor $f\maps T^n \to T$ in Th defines $n$ Gph-enriched natural transformations between these endofunctors, which represent typing inference rules:
\begin{center}
  \AXC{$X \entails t[]\maps Y$}
  \UIC{$X \entails f(t_1, \ldots, t_{i-1}, t[], t_{i+1}, \ldots, t_n)\maps f[t_1, \ldots, t_{i-1}, Y, t_{i+1}, \ldots, t_n] $} \DP $(t_{j\ne i} \in \mbox{Edge(Th)}) f_i,$
\end{center}
The identity and composition Gph-enriched dinatural transformations give the usual inference rules for identity and cut:  
\begin{center}
  \AXC{}
  \UIC{$X \entails []\maps X$} \DP $\quad$
  \AXC{$X \entails t[]\maps Y$} \AXC{$Y \entails u[]\maps Z$}
  \BIC{$X \entails u[t[]]\maps Z$} \DP.
\end{center}
We also get Gph-enriched dinatural transformations representing subtyping inference rules:
\begin{center}
  \AXC{}
  \UIC{$X \subseteq X$} \DP $\quad$
  \AXC{$X \subseteq Y$} \AXC{$Y \subseteq Z$}
  \BIC{$X \subseteq Z$} \DP $\quad$
  \AXC{$X \subseteq X'$} \AXC{$X' \entails t[]\maps Y$}
  \BIC{$X \entails t[]\maps Y$} \DP $\quad$
  \AXC{$X \entails t[]\maps Y$} \AXC{$Y \subseteq Y'$} 
  \BIC{$X \entails t[]\maps Y'$} \DP.
\end{center}
\begin{center}
  \AXC{}
  \UIC{$\bot \subseteq X$} \DP $\quad$
  \AXC{}
  \UIC{$X \subseteq X \lor Y$} \DP.
\end{center}

Each rewrite rule $\rho\maps f \Rightarrow f'\maps T^n \to T$ in Th defines $n$ Gph-enriched modifications on Spatial(Th, Coll), which represent proof normalization rules:
\begin{center}
  \AXC{$\Gamma \vDash (X \entails f(t_1, \ldots, t_{i-1}, t[], t_{i+1}, \ldots, t_n)\maps f[t_1, \ldots, t_{i-1}, Y, t_{i+1}, \ldots, t_n])$}
  \UIC{$\Gamma \vDash (X \entails f'(t_1, \ldots, t_{i-1}, t[], t_{i+1}, \ldots, t_n)\maps f[t_1, \ldots, t_{i-1}, Y, t_{i+1}, \ldots, t_n])$} \DP $(t_{j\ne i} \in \mbox{Edge(Th)}) \rho_i.$
\end{center}

\subsubsection{Soundness and completeness}
By soundness, we mean that anything one can prove using the type system is true of the collections.  By completeness, we mean that there are no collections that cannot be represented with a predicate.  The whole point of our approach is that it is correct by construction.  Soundness and completeness for the modal-free fragment follow directly from the definitions; soundness, in particular, is a direct consequence of the way realizability is incorporated into the approach.  For the formulae, the intuitions underlying the completeness argument amount to the fact that the term language for the logical operators associated with the collections are extractions of a term language for the collection monad.  Thus, they are in perfect correspondence with the model.  In the case of Heyt, this is equivalent to the well-known fact that boolean algebras are effectively realized by the powerset lattice.  Likewise, in the case of Heyt, the semantics that maps formulae to the composition of the collection monad with the monad for the term language supporting computation is nothing more than a pointwise lifting of the powerset semantics.   

\subsection{Modalities and behavioral types}

In order to get a Gph-enriched category that is not equivalent to the untyped one, we need to exclude certain morphisms that are not well-typed.  To capture well-typedness, we need modalities.  In what follows, we'll consider a generalization of the ``possibly'' modality typically denoted with a diamond $\diamond.$  The new modality is of the form $X\langle C, D \rangle Y,$ where $X$ and $Y$ are predicates, $C$ is a two-hole term context, and $D$ is a one-hole term context.  The parametric-possibly modality captures those terms that when placed in the context $C$ with a term of type $X$ possibly rewrite to a term of type $D[Y].$  For WHNF-SK, when we take $C[t,u] = (Rt\; u)$ and $D[v] = Rv,$ then $X\langle C, D \rangle Y$ is precisely the usual arrow type $X \Rightarrow Y.$  For \pic, we can choose $C$ to involve parallel composition rather than application; the parametric-possibly modality then becomes Caires' rely-guarantee modality $X \triangleright Y$ \cite{Caires}.  For simplicity, assume for this section that Coll = Heyt and our collections are finitely presentable subgraphs of $G.$

On the syntax side, we add new term constructors to Pred(Th).  Given a Lawvere theory $L$ with a sort $T$ for terms, one can derive a new theory $dL$ of term contexts by replacing each term constructor $f\maps T^n \to T$ with $n$ term constructors $f_i\maps T^{n-1} \to T$ where $1 \le i \le n$.  We think of $f_i$ as being $f$ with the $i$th input being a hole.  We define the Lawvere theory Modal(Th) to be Pred(Th) plus a new predicate constructor that takes two predicates $X$ and $Y,$ a two-hole term context $C,$ and a one-hole context $D$ and produces a new predicate.  As above, we generate a Gph-enriched category equivalent to $\End_{\Th}(T),$ but because we can now talk about the future behavior of terms rather than just their structure, this time we call it SpatialBehavioral(Th, Coll).

On the semantics side, we need a natural transformation from Modal(Th) to Heyt $\circ$ Edge(Th) that interprets a modal type as a set of edges satisfying that type.  We have the obvious functions src, tgt from Edge(Th) to vertices of G.  We define $\edge(x, y)$ for edges $x, y$ to be the set of edges from tgt($x$) to src($y$).  We extend $\edge$ to predicates by using the fact that our collection is a monad.  In Scala notation,
\[ \edge(X, Y) = \for(x \from X; y \from Y; r \from \edge(x, y)) \yield r. \]
The intepretation of the modality is
\[ \interp{X\langle C,D\rangle Y} = \for(t \from \top; r \from \edge(C[t, X], D[Y])) \yield t. \]

SpatialBehavioral(Th, Coll) comes equipped with extra subtyping inference rules involving the modality:
\begin{center}
  \AXC{$X \subseteq X'$} \AXC{$W \entails t[]\maps X'\langle C,D\rangle Y$}
  \BIC{$W \entails t[]\maps X\langle C,D\rangle Y$} \DP $\quad$
  \AXC{$W \entails t[]\maps X\langle C,D\rangle Y$} \AXC{$Y \subseteq Y'$} 
  \BIC{$W \entails t[]\maps X\langle C,D\rangle Y'$} \DP.
\end{center}
where we interpret $V, W$ in the last rule as $V \times W.$  The resulting system is sound by construction, but may not be complete because modalities may characterize sets that are not otherwise finitely presentable.

When $\edge(D[Y], C[\top, X])$ is not empty and we extend the modality from talking about single rewrites to talking about arbitrary lists of rewrites, we get inference rules like
\begin{center}
  \AXC{$W \entails t[]\maps X\langle C,D\rangle Y$} \AXC{$V \entails u[]\maps Y\langle C,D\rangle Z$}
  \BIC{$V,W \entails u[t[]]\maps X\langle C,D\rangle Z$} \DP
\end{center}
at the cost of potential divergence.

We leave the question of soundness and completeness of the ``eventually'' modalities for future work.

\section{Conclusion}

The modality-free fragment of our type system is sound and complete by construction.  It applies to any programming language with a formal operational semantics.  By virtue of following straightforward categorical principles, it extends the Curry-Howard-Lambek isomorphism to calculi that are not confluent and applicative.

We have applied this algorithm by hand to generate type systems for various calculi, including Rholang, the language of the new RChain project \cite{Rholang}.  We have found it powerful enough to reason about deniability in object capabilities systems; Meredith \cite{GregDAO} has shown that had the authors of the DAO contract on Ethereum been able to use such a type system, they could have detected the race condition before deploying the contract and avoided the \$50M DAO attack.  The algorithm also suggests a new way to monetize open-source software: first, authors of open-source code agree to license their code to a linking service.  A client programmer then specifies a predicate describing the behavior of the code she wants.  At linking time, a linking service employs a theorem prover to search a database of open-source code for functions or processes that satisfy the given predicate.  When the linking service provides a list of results, the programmer chooses the one she wants.  The linking service then debits the client's account and gives a cut to the author.

\section{Appendix}
\subsubsection{Gph-enriched category theory}
\label{GphReview}

Here we review some standard definitions and results in enriched category theory; see \cite{CIS-335497}, \cite{Power99EnrichedLawvereTheories}, \cite{LackR11}, and \cite{Trimble} for more details.

Let $C$ be a category, $X$ be an object of $C,$ and $X/C$ be the category of morphisms into $X$ and commuting triangles.  Let $\FinSet$ be a skeleton of the category of finite sets and functions between them.  A {\bf multisorted Lawvere theory} is a category with finite products Th equipped with a finite set $S$ of {\bf sorts}, and a functor $\theta\maps \FinSet^{\op}/S \to \Th$ that preserves products strictly.

A {\bf directed multigraph with self loops}, hereafter {\bf graph}, consists of a set $E$ of edges, a set $V$ of vertices, two functions $s,t\maps E \to V$ picking out the source and target of each edge, and a function $a\maps V \to E$ such that $s\circ a$ and $t \circ a$ are both the identity on $V$---that is, $a$ equips each vertex in $V$ with a chosen self loop.  A {\bf graph homomorphism} from $(E, V, s, t, a)$ to $(E', V', s', t', a')$ is a pair of functions $(\epsilon\maps E \to E', \upsilon\maps V \to V')$ such that $\upsilon\circ s = s' \circ \epsilon,$ $\upsilon\circ t = t' \circ \epsilon,$ and $\epsilon \circ a = a' \circ \upsilon;$ that is, a graph homomorphism maps edges to edges and vertices to vertices such that adjacency and self-loops are preserved.  {\bf Gph} is the category of graphs and graph homomorphisms.  Gph has finite products: the terminal graph is the graph with one vertex and one loop, while the product of two graphs $(E, V, s, t, a) \times (E', V', s', t', a')$ is $(E \times E', V \times V', s \times s', t\times t', a \times a').$

A {\bf Gph-enriched category} consists of
\begin{itemize}
  \item a collection of objects;
  \item for each pair of objects $x, y,$ a graph $\hom(x,y);$
  \item for each triple of objects $x, y, z,$ a composition graph homomorphism $\circ\maps \hom(y, z) \times \hom(x, y) \to \hom(x, z);$ and
  \item for each object $x,$ a vertex of $\hom(x, x),$ the identity on $x,$
\end{itemize}
such that composition is associative, and composition and the identity obey the unit laws.  A Gph-enriched category has finite products if the underlying category does.

Any category is trivially Gph-enrichable by treating the elements of the hom sets as vertices and adjoining a self loop to each vertex.  The category Gph is nontrivially Gph-enriched: given two graph homomorphisms $F, F'\maps (E, V, s, t, a) \to (E', V', s', t', a'),$ a {\bf graph transformation} assigns to each vertex $v$ in $V$ an edge $e'$ in $E'$ such that $s'(e') = F(v)$ and $t'(e') = F'(v).$  Given any two graphs $G$ and $G',$ there is an exponential graph $G'^G$ whose vertices are graph homomorphisms between them and whose edges are graph transformations.

A {\bf Gph-enriched functor} between two Gph-enriched categories $C, D$ is a functor between the underlying categories such that the graph structure (adjacency and chosen self loops) on each hom set is preserved.  

A {\bf Gph-enriched natural transformation} between two Gph-enriched functors 
\[\alpha\maps F \Rightarrow G\maps C \to D\]
assigns to each object $c$ of $C$ a morphism $\alpha_c\maps Fc \to Gc$ of $D$ such that for any edge $e\maps f \Rightarrow f'$ in the graph $C(c,c'),$
\[\alpha_{c'}\circ Fe = Ge \circ \alpha_c.\]

A {\bf Gph-enriched modification} between two Gph-enriched natural transformations
\[\Gamma\maps \alpha \Rrightarrow \beta\maps F\Rightarrow G\maps C\to D\]
assigns to each object $c$ in $C$ an edge $\Gamma_c\maps \alpha_c \Rightarrow \beta_c$ in the graph $D(Fc, Gc).$

\begin{thebibliography}{99}

\newcommand{\quantph}[1]{\href{http://arxiv.org/abs/quant-ph/#1}{{ arXiv:quant-ph/#1}}}
\newcommand{\hepth}[1]{\href{http://arxiv.org/abs/hep-th/#1}{{ arXiv:hep-th/#1}}}
\newcommand{\grqc}[1]{\href{http://arxiv.org/abs/gr-qc/#1}{{ arXiv:gr-qc/#1}}}
\newcommand{\qalg}[1]{\href{http://arxiv.org/abs/q-alg/#1}{{ arXiv:q-alg/#1}}}
\newcommand{\mathph}[1]{\href{http://arxiv.org/abs/math-ph/#1}{{ arXiv:math-ph/#1}}}
\newcommand{\Math}[1]{\href{http://arxiv.org/abs/math/#1}{{ arXiv:math/#1}}}
\newcommand{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{{ arXiv:#1}}}

\bibitem{Closure} \href{https://developers.google.com/closure/compiler/}{https://developers.google.com/closure/compiler/}
\bibitem{Flow} \href{https://flow.org/}{https://flow.org/}
\bibitem{Rholang} \href{https://github.com/rchain/Rholang}{https://github.com/rchain/Rholang}
\bibitem{kframework} \href{http://kframework.org}{http://kframework.org}
\bibitem{Maude} \href{http://maude.cs.illinois.edu/}{http://maude.cs.illinois.edu/}
\bibitem{MyPy} \href{http://mypy-lang.org/}{http://mypy-lang.org/}
\bibitem{TypeScript} \href{https://www.typescriptlang.org/}{https://www.typescriptlang.org/}
\bibitem{PoplMark} B.\ E.\ Aydemir, A.\ Bohannon, M.\ Fairbairn, J.\ N.\ Foster, B.\ C.\ Pierce, P.\ Sewell, D.\ Vytiniotis, G.\ Washburn, S.\ Weirich, S.\ Zdancewic, ``Mechanized Metatheory for the Masses: The PoplMark Challenge,'' in {\em Theorem Proving in Higher Order Logics}, eds. J.\ Hurd and T.\ Melham. TPHOLs 2005, LNCS {\bf 3603}. Springer (2005)
\bibitem{Boudol} G.\ Boudol, ``The pi-calculus in direct style,'' POPL'97 (1997) 228--241.
\bibitem{Milner} Robin Milner, ``The Polyadic {pi-Calculus}: A Tutorial,'' in {\em Logic and Algebra of Specification,} eds. F.\ L.\ Hamer, W.\ Brauer, and H.\ Schwichtenberg, Springer-Verlag (1993).
\bibitem{Caires} Lu\'is Caires, ``Behavioral and Spatial Observations in a Logic for the pi-Calculus.''  FoSSaCS 2004, LNCS {\bf 2987}, (2004) 72--89.
\bibitem{Clouston} R.\ Clouston, ``Nominal Lawvere Theories: A category theoretic account of equational theories with names,'' {\em Journal of Computer and System Sciences} {\bf 80} (2014) 1067--1086.
\bibitem{GabbayPitts} M.\ J.\ Gabbay and A.\ M.\ Pitts, ``A New Approach to Abstract Syntax with Variable Binding,'' {\em Formal Aspects of Computing} {\bf 13}, (2001) 341--363.
\bibitem{CIS-335497} J.\ W.\ Gray, ``Review: G. M. Kelly, Basic concepts of enriched category theory,'' {\em Bulletin of the American Mathematical Society} {\bf 9(1)}, (1983) 102--107 
\bibitem{Lack2010} S.\ Lack, ``A 2-Categories Companion'' in {\em Towards Higher Categories,} Springer New York (2010) 105--191.
\bibitem{LackR11} S.\ Lack and J.\ Rosick{\'{y}}, ``Notions of Lawvere Theory,'' {\em Applied Categorical Structures} {\bf 19(1)} (2011) 363--391.  Also available at \arxiv{0810.2578}.
\bibitem{Lambek} J.\ Lambek, ``From $\lambda$-calculus to cartesian closed categories,'' in {\sl To H.\ B.\ Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism}, eds.\ J.\ P.\ Seldin and J.\ R.\ Hindley, Academic Press, (1980) 375--402. 
\bibitem{Lawvere} F.\ W.\ Lawvere, {\sl Functorial Semantics of Algebraic Theories}, Ph.D.\ Dissertation, Columbia University, 1963. Also available at \href{http://www.tac.mta.ca/tac/reprints/articles/5/tr5abs.html}{http://www.tac.mta.ca/tac/reprints/articles/5/tr5abs.html}.
\bibitem{GregDAO} L.\ G.\ Meredith, ``DAO bug typing,'' \href{https://docs.google.com/document/d/1sGlObhGhoEizBXC30Ww4h1KHKGkmcy4NiCKitIBqiUg/edit}{https://docs.google.com/document/d/1sGlObhGhoEizBXC30Ww4h1KHKGkmcy4NiCKitIBqiUg/edit}
\bibitem{MeredithRadestock} L.\ G.\ Meredith and M.\ Radestock, ``A Reflective Higher-order Calculus,'' {\em Electronic Notes in Theoretical Computer Science} {\bf 141} (2005) 49--67.
\bibitem{Power99EnrichedLawvereTheories} J.\ Power, ``Enriched Lawvere Theories,'' {\em Theory and Applications of Categories,} {\bf 6(7)} (1999) 83--93.  Also available at \href{http://www.tac.mta.ca/tac/volumes/6/n7/6-07abs.html}{http://www.tac.mta.ca/tac/volumes/6/n7/6-07abs.html}.
\bibitem{Trimble} T.\ Trimble, ``Multisorted Lawvere theories,'' $n$Lab.  Available at \href{http://ncatlab.org/nlab/show/bicartesian+closed+category}{http://ncatlab.org/nlab/show/bicartesian+closed+category}.
\bibitem{Yoshida} N.\ Yoshida, ``Minimality and separation results on asynchronous mobile processes â€“ representability theorems by concurrent combinators,'' {\em Theoretical Computer Science} {\bf 274} (2002) 231--276.

\end{thebibliography}
\end{document}
